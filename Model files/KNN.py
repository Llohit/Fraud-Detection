# -*- coding: utf-8 -*-
"""knnearest-0-53.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YO6nEV4Cd5-Rm-CWhPZXRQk7A534fRVP
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

df2=pd.read_csv("../input/fraudaa/newdf2.csv")

ntese=pd.read_csv("../input/fraudaa/newtest.csv")
dte=pd.read_csv('../input/its-a-fraud/test.csv')

df2.drop(['Unnamed: 0'],axis=1,inplace=True)
ntese.drop(['Unnamed: 0'],axis=1,inplace=True)

X_test=ntese.copy()

df2.drop(['TransactionID'],axis=1,inplace=True)
X_test.drop(['TransactionID'],axis=1,inplace=True)

X=df2.drop(['isFraud'],axis=1,inplace=False)
y=df2['isFraud']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.33, random_state=42)

Counter(y_train)

from sklearn.neighbors import KNeighborsClassifier

score=[0 for i in range(2,11)]
for k in range(2, 11):
    print(k)
    clf = KNeighborsClassifier(n_neighbors = k)
    clf.fit(X_res, y_res)
  
    #training_score = clf.score(X_train, y_train)
    test_score = clf.score(X_test, y_test)
    score[k]=test_score
    print(score[k],"sc")

score.append(test_score)

clf = KNeighborsClassifier(n_neighbors = 10)
clf.fit(X_res, y_res)
test_score = clf.score(X_test, y_test)

score.append(test_score)

print(score.index(max(score)))

from sklearn.neighbors import KNeighborsClassifier

knn=KNeighborsClassifier(n_neighbors=2)
knn.fit(X_res1,y_res1)

predhyp=knn.predict(X_test)

Counter(predhyp)

y.shape

X_test.shape

y_pred = knn.predict(X_test)

from collections import Counter

Counter(y_pred)

ntese['IsFraud']=predhyp

neww=ntese[['TransactionID','IsFraud']]

dte = dte.merge(neww, how='outer',copy=False, on ='TransactionID' )

dte['IsFraud']

y_predd=dte['IsFraud']

Counter(y_predd)

y_predd.to_csv('y_pred20.csv')

X_train=df2.drop(['isFraud'],axis=1,inplace=False)
y_train=df2['isFraud']

Counter(y_train)

"""Hybrid under sampling and over sampling"""

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline


over = SMOTE(sampling_strategy=0.1)
under = RandomUnderSampler(sampling_strategy=0.5)

steps = [('o', over), ('u', under)]
pipeline = Pipeline(steps=steps)

X_res, y_res = pipeline.fit_resample(X_train, y_train)
X_res1, y_res1 = pipeline.fit_resample(X, y)



#smote = SMOTE(0.75,random_state=42)
#X_res, y_res =  smote.fit_resample(X_train,y_train)
#X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.25, random_state = 42)

X_res1.shape

from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier



p = Pipeline([('Normalizing',MinMaxScaler()),('KNeighborsClassifier',KNeighborsClassifier(weights='distance', n_neighbors=5, n_jobs=-1))])
p.fit(X_res,y_res)

from sklearn.neighbors import KNeighborsClassifier

neigh = KNeighborsClassifier(weights='distance', n_neighbors=5, n_jobs=-1)
neigh.fit(X_res, y_res)

y_pred=p.predict(X_test)